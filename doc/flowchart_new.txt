A. ğŸ‘¤ User Input
   â†“
A1. ğŸ§  Router (Input Routing & Intent Detection)
   â”œâ”€â”€ If tool command â†’ A2. ğŸ› ï¸ Tool Handler
   â”‚       â”œâ”€â”€ Uses `tool_registry.py`
   â”‚       â””â”€â”€ Calls tool like `image_gen.generate(prompt)`
   â”‚            â†“
   â”‚         â†’ E. ğŸ—£ï¸ Response (Tool Output)   
   â””â”€â”€ Otherwise
       â†“
B. ğŸ§  Engine
   â”œâ”€â”€â†’ B1. ğŸ§  Short-term Buffer
   â”œâ”€â”€â†’ B2. ğŸ” Qdrant (Semantic Search)
   â”œâ”€â”€â†’ B3. ğŸ“Š PostgreSQL (Facts, Logs)
   â”œâ”€â”€â†’ B4. ğŸ•¸ï¸ Neo4j (Topics, Entities)

       â†“
C. ğŸ“¦ Context Builder
   â””â”€â”€ Builds full prompt incl. memory, persona, emotional tone (analysis/emotion_handler)

       â†“
D. ğŸ§  LLM (Prompt + Input)
   â””â”€â”€ Output text + (Optional) tool triggers or suggestions
       â†“
D2. ğŸ§  Router (Post-LLM Tool Detection)
   â”œâ”€â”€ If LLM suggests a tool â†’
   â”‚     â†’ A2. ğŸ› ï¸ Tool Handler
   â””â”€â”€ Otherwise â†’
       â†“
      AND â†’ Send answer to databases through Engine
       â†“

E. ğŸ—£ï¸ Response (Final message to user)

       â†“
F. Logging and Memory Update
   â”œâ”€â”€â†’ F1. ğŸ“ PostgreSQL (Log + Metadata)
   â”œâ”€â”€â†’ F2. ğŸ“¥ Qdrant (Embedding)
   â”œâ”€â”€â†’ F3. ğŸ“ˆ Neo4j (Topic graph update)
          â†“
G. ğŸ§¬ Echo Corpus (training base)

--------explanation----------

| Component                   | Description                                                                                                                                                                                                                   |
| --------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **A1: Router (pre-engine)** | Routes based on command (e.g., `/image`, `/tool`, `/persona`). Fast bypass for known commands. If no command detected, passes to engine.                                                                                      |
| **D2: Router (post-LLM)**   | Routes based on model output. If model generates tool trigger (e.g., â€œcall\_tool\:image\_genâ€), it goes here before final response.                                                                                           |
| **Emotion-Driven Routing**  | Could sit inside the **engine** or **router**, depending on implementation. For example: if the emotion analyzer sees the user is sad â†’ it can inject a tool call (like image\_gen) into the flow before the LLM even speaks. |

----------------------------
TOOL-HANDLER:
A2: Tool Handler
This is the component that executes a specific tool function (e.g., image_gen.generate(), web_search.search(), or sandbox_env.run_code()).
Itâ€™s triggered either by:
A direct user command (e.g., /generate_image dog in a jetpack)
A Router decision after LLM suggests tool usage

shared/tools/image_gen.py
shared/tools/web_research.py
shared/tools/sandbox_env.py
shared/tools/tool_registry.py
So, A2 == a runtime handler that dispatches to these tool modules via tool_registry.py.
-----call stack-----
[router.py]
  â””â”€â”€ if tool is invoked:
      â””â”€â”€ A2: Tool Handler = tool_registry.get("image_gen") â†’ image_gen.generate()
----sample router.py ----
from shared.tools.tool_registry import get_tool

def handle_tool_request(command, args):
    tool_func = get_tool(command)
    if tool_func:
        return tool_func(args)
    else:
        return f"Tool '{command}' not found."
-----
router.py should:
Detect /toolname commands (e.g., /generate_image)
Pass them to tool_registry.py
A consistent input format (e.g., /generate_image prompt="cat with hat")
Have a fallback that passes non-tool inputs to engine.py with some code that tells engine the tool-input failed
